name: Job Scraper

on:
  schedule:
    # Run every 6 hours
    - cron: '0 */6 * * *'
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Run in test mode (only 3 companies)'
        required: false
        default: 'false'
        type: boolean

env:
  PYTHON_VERSION: '3.11'

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Install Playwright browsers
        run: |
          playwright install chromium
          playwright install-deps chromium
      
      - name: Set up Google credentials
        run: |
          echo '${{ secrets.GOOGLE_CREDENTIALS }}' > credentials.json
        working-directory: src
      
      - name: Run job scraper
        env:
          COMPANIES_SHEET_ID: ${{ secrets.COMPANIES_SHEET_ID }}
          JOBS_SHEET_ID: ${{ secrets.JOBS_SHEET_ID }}
        run: |
          if [ "${{ github.event.inputs.test_mode }}" = "true" ]; then
            python main.py --test
          else
            python main.py
          fi
        working-directory: src
      
      - name: Clean up credentials
        if: always()
        run: rm -f credentials.json
        working-directory: src
